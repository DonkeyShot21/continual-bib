# Inspiring Continual Learning
A curated list of inspiring Continual Learning (aka Incremental Learning) resources.

### <a name="datasets"></a>Datasets
| Name | Resolution | Classes | Images | Size | Times Used |
|:-:|:-:|:-:|:-:|:-:|:-:|
| <a name="cifar-10"></a>[MNIST][web:mnist] | 28x28 | 10 | 70k | 20 MB | 0 |
| <a name="cifar-10"></a>[CIFAR-10][web:cifar] | 32x32 | 10 | 60k | 160 MB | 0 |
| <a name="cifar-100"></a>[CIFAR-100][web:cifar] | 32x32 | 100 | 60k | 160 MB | 0 |
| <a name="cifar-1000"></a>[ImageNet-1000][web:imagenet1000] | 469x387* | 1000 | 1.2M | 154 GB | 0 |

[web:mnist]:http://yann.lecun.com/exdb/mnist/
[web:cifar]: https://www.cs.toronto.edu/~kriz/cifar.html
[web:imagenet1000]: http://www.image-net.org/download-images

\* on average, though images are usually downscaled to 256x256

### <a name="formatting"></a>Formatting
Papers are organized in chronological order. Each entry should be formatted as below:

---

<a name="paper_id"></a>**[Name of the Paper][paper:paper_id]**
<br/>
<span style="color:grey">Authors</span><br/>
Name of the conference, Year<br/>

| Category | Code | Inspiration Score |
|:-:|:-:|:-:|
| pure <br/> exemplars <br/> generative <br/> meta | [:atom:][code:paper_id] nice code <br/> [:toilet:][code:paper_id] bad code<br/> :skull: no code | :poop: very bad <br/> :face_with_head_bandage: bad <br/> :neutral_face: ok <br/> :star: good <br/> :fire: very good <br/> :thinking: not sure |

**Summary:**<br/>
three to five lines summary goes here.

**Comment:**<br/>
three to five lines comment goes here.

**Datasets:** list of datasets they use with link to dataset table


[paper:paper_id]: https://arxiv.org
[code:paper_id]: https://github.com

---
